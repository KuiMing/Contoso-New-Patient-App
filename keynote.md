These, these models, right, you've got text to speech, you've got rather, I should say, a text to image with Dali, you've got coding, you've got language. Your ChatGPT has completely changed the conversation about AI. I think those of us who have been on the inside of a I definitely have kind of thought about it. It's like of course it's it's changing the world and we see it every day. But I think ChatGPT made it real for millions of people by showing them what it can do and how powerful it is and their imaginations are now freed. How can this be really useful toward someone who may have say, limited mobility. One of my colleagues Christina, her arms are paralyzed and she types with her toes and watching her use this product is really cool because she said, oh, I know, just have to type one sentence rather than typing lots of. It's just to plan a trip. For example, you know, how do we set the right mental model for a technology like this? You know, it's super impressive. It can create, it can cite information. And so we found that people tend to over trust or over rely the kind of information it it, you know, generates. And so a lot of what our team did was like, how do you set the right mental model for users, reminding them, hey, you know, this is from the Internet, just as reliable as the Internet. Some things are factual, some things are not. So hi everyone, welcome to the global AI Boot Camp 2023. We welcome you as one of the attendees of our yearly global event with more than 70 locations around the world. This Sammy, do you know that this is already the 5th? Event in Row 5 already. Yes. OK, it's our fifth anniversary. Wow, that's that's crazy. Time really flies. Yeah. We started in 2018 together with the global XRP community, and then in 2019 it really exploded with lots of locations around the globe. Then we had a couple of years, which were virtual and some were hybrid. And now we're back with our fifth anniversary, a big event with lots of locations around the world. It's, uh, it's really a nice history already. But I think there's a lot of people also that we need to thank. And actually those people are right now together with you and the room, and that's the local organizers. They've been working hard to find a venue, to find speakers, to find sponsors or maybe even catering for some food. So please thank all, thank you to all the local organizers. Give them a random applause for for all the work that they've been doing. I think they're really earnest to be doing because of doing all that kind of work. Yes, thank you. Yeah. But you know, there's also some other people who've been doing a lot of work over the last five years and one person specifically. Well, it's sad that you cannot see him, but we can see him. So give me a second. We switch on my phone and my camera. Here. You see this guy here? He's one of the founding fathers of the global AI community and has been working for us for over 5 years, of course doing everything. And now somehow he found a new. Fashion and producing videos like this. So should we go inside? Let's go. OK, let's go. Come on inside. So hi, John. Welcome to the global AI bootcamp keynote. Hi. Thank you very much for having me. Yes, and thank you for being here with me. It's my pleasure. Yeah. Before we start, can you tell us who you are and what you do at Microsoft? Sure. I'm John Montgomery, and I am the corporate vice president of product in charge of Azure AI, which includes the Azure cognitive Services, Azure Open AI service, Azure machine learning and our AI frameworks. So if we look at the past year, what is your most memorable moment in terms of AI advancements? The last year has been amazing. I tend to think about the world in terms of customer impact more so than like research impact or product advances. And in the last year, I would say we've seen several interesting customer things happen. One of the biggest. I mean, I could, I could pick. Ohh, well, so they're, they're little ones like the improvements we've seen in our cognitive like neural voices. The quality is getting better, it's taking less training data and that's enabled customers like Duolingo to add languages and to make the interactions kind of more personal. We've done a whole bunch inside of Azure machine learning to make it scale better, to make training better and that's impacted a bunch of customers ranging from big ones like Chevron to some of our newer customers. I I think though if you look back at the last year, probably the single kind of biggest thing is around Azure open AI service going general availability and ChatGPT and those are probably the biggest things in the last year ChatGPT has completely changed the conversation about AI. I think those of us who have been on the inside of a I definitely have kind of thought about it as like of course it's changing the world and we see it every day but I think ChatGPT. Made it real for millions of people by showing them what it can do and how powerful it is. And their imaginations are now freed. Yeah, that's still true. Life used it for a couple of Times Now and it is really, really big and it's really game changing. I have to ask you then, what's the coolest thing you've done with ChatGPT? I have written some social media posts for my podcast. It's very good at it. Even better than I am. It is very good at things like that. Yes, that's totally true. You also lead A-Team at Microsoft, and that team focuses on building tools that are used by customers to create their own AI solutions. So can you share a customer story with us that really stood out for you? Wow, um. So there are. So when I think about my customers, I really kind of think about it in two cohorts. Microsoft is actually my largest customer. All of the AI services at Microsoft, they're using Azure machine learning for training or for inference. They're calling our cognitive services. They're using Azure open AI service. And that includes things like GitHub copilot, which is built on Azure Open AI. It includes things like dynamics 365. I think though from a first party perspective in the last few days we've seen some really huge announcements. There was one that actually happened just today where we're seeing the potential of ChatGPT like things in Bing. We've also seen a massive announcement around Viva sales and teams premium. We've been working for years with the teams team to do transcription of meetings and that transcription. And drive things like closed captioning, but we haven't tapped the full potential until teams premium came out and now you can get meeting summaries sent to you and action items assigned to you in teams and that's just showing the power of what AI can do. So from a first party perspective, I think that one is super interesting. From a kind of a third party customer perspective, you know I'm going to pick a totally different one. And I would, I would focus more on. The impact that some of our responsible AI tooling has had the National Health Service in the UK has been completely inundated since the start of COVID. And they have been using the responsible AI tools inside Azure machine learning to help Dr. Clarity and confidence in some of the machine learning models they've created to figure out where surgery patients should go for their hip and knee surgeries, whether they need to go to a major. Medical Center or they can go to a smaller Regional Medical Center based on a risk assessment profile. And so, you know, obviously helping customers is huge. And that was just an amazing example of basically doctors kind of working with their data science teams to help an immediate and local problem using the tools my team creates. What do you think are the three topics that people should be educated in? I'd say I'd call out three things and actually it might be the same even if I were talking to. Like my sister who is an educator in Germany. The first thing is understanding responsible AI, understanding safety, understanding regulation and understanding kind of the current truth and the current lay of the land around these large language models. There is a huge amount of fear, uncertainty and doubt out there being spread by everything from competitors to folks who just don't know anything. The regulations are changing very, very quickly and the technology is changing very quickly. I think understanding. Understanding responsible AI, what it means, understanding what Microsoft is doing is probably first and foremost on the list and making it real because it is going to change very quickly. But that knowledge is the foundation of kind of answering a bunch of questions about things. I think the second thing that I would point to as something everybody should know about is kind of large language models and this evolution we're seeing around what you can do when you can't actually take a model and retrain it from scratch. I think we've trained ourselves over the years that the only way you can do powerful things with a model is retrain it from scratch on your own data. These models, it doesn't work that way. I mean, these models take months to train on supercomputers. Right. And I think now we're starting to give people fine tuning APIs and more and more tools on top of it, understanding what you can do with these understanding prompt engineering and what's coming after that. That is kind of a major thing for everybody. The third one is actually more kind of a longer lead pair of technologies. The first one of that is reinforcement learning and then the second one in is privacy preserving training or Federated learning. And these may be like the nuclear fusion of artificial intelligence. We've been talking about them for years and we're starting to see point applications. I think the chat GPTS use of rohff is starting to cause a lot of more interest in reinforcement learning. And certainly as we roll these models out more and more dealing with the questions about how do you actually fine tune a model without needing to take the data back to the source is something that we're going to have to think about more and more. So knowing about those two categories of technology is, is probably. A useful background thread. It's not immediately practical for most developers or data scientists or IT admins, but knowing what they are and basically how they work is probably another good foundational thing for folks to understand. Sounds like lots of good things to dive into for IT pros, developers, data scientists. Absolutely, yes. Thank you so much, John, for being here with me. It's been great to be here. Thank you. Well, that was a very interesting conversation you had with John. He really showed us what the strategy Microsoft has for implementing AI in their products and also the future that they are looking into. But also he shared this three different topics that can help us to learn more about AI. Yes, that was really valuable. And he also briefly mentioned open AI and that's what you're going to focus on together with Bob, right? Really looking forward to that conversation. Yeah. Thank you, Bob, so much for making time for a quick chat. Um, could you introduce yourself for the people who don't know? Sure. Well, it's a pleasure to be here. My name is Bob Reinhart. I'm within the Microsoft AI platform engineering organization, and myself and my team have the fun of engaging with customers and partners all over the world to bring them on to Azure. Open AI service customers, partners, MVPS. Can you explain to people what open AI exactly is? Yeah, so open AI. It's the latest in the series of models that produced by open AI. Or large language models, they're generative models, they're transformer models. And really what that means is instead of taking a smaller purpose built model, you know, something that does text analytics, something that does translation, it basically has multiple capabilities built into the service itself. So in the case of open AI has fantastic language capabilities with the GPT 3 models. Also one of the cousins of that is ChatGPT, which is really captured the hearts and the minds of everyone around the world. And there's also the ability to do text to image with the Dali model and then. You know last, we have codecs, extremely important really to democratize software development and providing people access to SQL databases that aren't SQL devs. So it's just brings all of these different capabilities together through a single API and it's super powerful because it enables people to take what they would have been using like 678 pre built task specific models and then use the open AI service to do a whole variety of tasks. We call this model as a platform. So it's really a platform to build applications on top of, OK. I can imagine with the services now open to the public, the information that is putting in by the public is also very interesting to make use to improve new models. Yeah, now that's a great point because with our friends at open AI, yeah, when ChatGPT is learning, millions of peoples are using it. That feedback goes right into training the next instance of the model and it's really powerful because it builds in real time feedback. And like one of the thick common things we get with enterprise customers is they don't want their data to go into the model. I think I know where this was going. And so you know we do have that enterprise promise in Azure that your data is your data. Yes, you can use your data to train the model, but enterprises, company secrets and so forth are not going to go back into the model training. But so we have the best of both worlds. We have open AI, continually retraining and then our enterprise customers with that sort of data security. Value that we prepare, which is very important of course. Well, it's quite interesting. Now we've we've been talking about Azure Open AI, but there's also just open AI. What exactly is the difference? Yeah, now that's a great question. Yeah, I always like to start off just by talking about what is the same. First of all, every open AI model that's released is trained on the Azure supercomputer. So think of open AI as an Azure ISV of sorts, very strategically important one. But nevertheless, they're very similar to other partners we have, right, in terms of just sitting on that Azure infrastructure. And then same with, of course, Azure open AI service, a completely separate instance of Azure infrastructure. But still both sit on that. So that's similarity #1, similarity #2, it's the same models. Yeah, these models are stochastic. You will get different responses if you ask the same question multiple times. You'll get that with open AI as well as across open AI and Azure open AI. But the models are exactly the same. They're the same. You know, code base, the same instances of the models. When you get text to MINCI 003 on open AI, you can take that work, reproduce it again within the stochastic characteristics of the models and get the same type of responses. So we see customers working on open AI and then directly transferring that knowledge over to Azure open AI service very seamlessly. We have one customer, treliant, a startup, who moved from open AI to Azure open AI, he said it was literally 3 lines. Code to change his app to be able to use Azure open AI. Couple of things on the differences, you know, customer customer reference is super important to us. We love when customers work on open AI, but we see with the largest enterprise customers and also Isvs that work with enterprise is there are certain security features and enterprise features that companies need to take something into production. There's also regulatory compliance. So if you look at it from a security perspective, we support the Azure networking like Express route and private links we support. You know, we have this data security policy that your data is your data. We also the service is HIPAA compliant for like healthcare companies, Sock 2 compliant. So regulatory compliance is also super important. One of the other major differences is geodiversity. We do offer Azure open AI service in multiple Azure regions around the world. So what you're actually doing, you have the open AI services, you're building a nice layer on top of it with extra security, making sure it's in different regions actually bring it to an enterprise level. So we've talked now. How enterprise organization are already making use of these services. Can you give us any example use case, ohh, yeah, absolutely. So we see with use cases, the language use cases are grouped into four sort of buckets or broad categories. The first we call reason over structured and unstructured data and the beginning we were kind of looking at all these different model capabilities and they're basically classification, sentiment, these type of classification, search and then entity extraction and we say what are people? Actually doing well. They're getting reasoning. They're gathering reasoning over data over structured and unstructured data. And then that usually feeds into other model capabilities where customer will take a call center record, do those types of things and then use the summarization capability. So summarization is the other use case category very common with call center transcripts, large technical documents, etc. The third one is conversational AI, and I don't need to explain that. You can look at ChatGPT and see. The amazing capabilities that we have there. So the other one is writing assistance companies that are using open AI to basically write blog posts. A lot of people on this audience will have children that are using it to write homework assignments. It is done out there. And then also we see a lot in marketing campaigns for developing taglines, for e-mail headers, etc. So there are a few case studies that were out there. I mentioned Treliant CarMax is a customer that's been using it. To summarize, you know thousands of. Automobile reviews down to a very coherent description, you know, saving thousands of hours of, you know, collating all that information together. And we have farm lands out of New Zealand who's actually using it to look at the sentiment of their agriculture retail customers. Really interesting use case. I mentioned treliant. What they're doing is they're using Codex model to generate DOC strings for code, documentation for legacy code. So there's a lot of really interesting customer engagements out there and more to come. Yeah, I can imagine. That it's, uh, it's an interesting times that are coming with all the new things that are coming up. Well, linked to that, how do you think the future of opening eye services is going to be? Yeah. I mean, the future happens every minute. I think we heard some announcements today, you know, about incorporating open AI into Bing search. So yeah, it's a very, very fast moving space, but there's really a few key areas. One is responsible AI and we'll cover that in a bit. The second is if you take a look at these models, right, you've got text to speech, you've got rather, I should say, text to image with Dali, you've got coding, you've got language. Multimodal is something that we're looking at. Moving forward where these multiple model capabilities are all converging onto sort of a single single model, single API. So that's something to look forward to. Also you know being used for more forward-looking like external users, social media type things right now responsible AI is a bit of concern just because these models are generative and we have to take the responsible AI and really test it out over time. But I think we're going to start seeing it much more wide used in that as well as in mission critical applications. I mean Azure open AI service is built for those types of enterprise deployments, but really the big things are multimodal. And also some of the advancements in responsible AI. OK, well, you already answered my last question a bit concerning responsibility. I I think that's something we really need to look more into because it's so important. But Bob, I can only thank you for this very nice conversation and I'm really looking forward to what open AI is really going to bring in the next coming levels next weeks, months and for Microsoft and also for the world. Thank you very much. Thank you for having me. So Bob really told us a lot of exciting stuff about open AI. This is really going to be a huge game changer in the tech industry. Yeah, I'm really looking forward to everything that this is going to bring in the upcoming years for sure. I'm also looking forward to that. But I think our next guest will really giving us an example how open AI has been embedded in a business application. Let's have a view also on that. Let's do that. Hey, Sharon, thank you for joining me today. I hope you are doing well. Yeah, thanks for having me. Well, I've heard. We've been working also on the release of Bing Open AI, the combination of it. Can you tell us a little bit more about it? Yeah, it's been super exciting. We've seen the buzz all this week and our team really came in towards the end of last year really thinking about the responsible AI. And you know, how do we think about the societal implications of releasing something like this following the ChatGPT launch and the excitement over it? Well. Since you are focused on the ethical part of AI, what were the things you really had to look into and releasing a product like that? Yeah, I think the initial version was really about understanding how do we set the right mental model for a technology like this? It's super impressive. It can create, it can cite information. And so we found that people tend to over trust or over rely the kind of information it it, you know, generates. And so a lot of what our team did was like how do you set the right mental model for users reminding them. Hey, you know, this is from the Internet, just as reliable as the Internet. Some things are factual, some things are not. And so that was our initial step was really around education, around user transparency and so, but there's so many more places that we want to go to in terms of what is the future human AI interaction model that we really want to create with the technology like this. OK, that's quite interesting. Now the tool, that's the model that is used behind the service is chat CPT where it consumes. A lot of data to get trained, right? How does it get curated that the data is, for example, unbiased? Yeah. So there's like a slight note where it's actually not using the ChatGPT 3 model directly, it's actually using something called Prometheus, which was a joint model that was created from Bing and Open AI to really tailor ChatGPT, but for search scenarios. So for example, limitations of ChatGPT is that it doesn't have current events, right. If you use it on open AI, it's limited to like I think the end of 2021. Prometheus now allows like actual grounding, that against beings existing search index. You know, so you have a grounding event information, you're able to actually have citations, it's able to point to the sources it's referencing and so those are the new things in terms of. Bias. But like I said, you know, this is based off of the Internet and so there's a lot of biases inherently woven into the Internet. And so it's a little bit, it's inescapable for it to be able to replicate some of those biases. I would say on the platform level, there's been a lot of work in terms of safety like content moderation. You know, how do we think about safe inputs and outputs if users tend to ask, you know, being like, hey, you know, I got this, you know, prescription from my medication. Does that look right? It will, you know, tell you, hey, you should consult the medical professional. And so we had to think about those kind of safety scenarios as well. Yeah. Now I have a question also concerning what a company needs to do to get an ethical AI strategy. But I think it's a good idea to also get a little bit more clear overview of what ethical AI exactly is. Yeah, that's it. That's a loaded question. I think there's so many aspects to that. I would say with ethical AI, it's not about right or wrong, right, because you know, you're. Ethics are different from my ethics and you know, how do we really determine what that is, especially for a company like Microsoft. You know, we're an international company with international consumers. And so when we say ethics, we're really about how do we be really intentional about what we build when we build something, how do you think about not just its initial impact but the 2nd order implications. And so again it's that word implications. How do you think about the deeper consequences, you know, how do we think about not just your direct customers? That like who is affected by your product even though they don't necessarily use it. You know for example back to the ChatGPT scenario, if people are using it for medical professionals, even if doctors aren't, you know directly using it, it might affect them because you know their patients might not be going to them and say hey I got this prescription or does diagnosis, what do you think? And so we think about those different layers and so I think for a lot of companies for ethical AI strategy it's investing in that longer tail consequences because. Those longer term things will affect you and just being more intentional about, you know, thinking about the consequences and implications of what you're building. OK, what advice would you be able to give organizations that want to implement AI in their solutions? I honestly think, I do think it's really about, you know, the innovation part is what's captivating everybody but really thinking about not just the application but the implications. And when you talked about your earlier question of how do you build an ethical AI strategy, I think at the core of the culture and the leadership, you need to believe that's important. You know, it's not always easy because ethical AI, you might not see the bottom line, you know, impact right away, but on the long scale. You know, at Microsoft at least we take it so seriously because you know, we're not just a company here for the next 10 years, we hope to be around for a much longer time and to do that we have to be building towards a better society for that to exist. OK. Thank you very much for this nice answers on the on my questions. Looking forward to seeing more of you and your team also read articles or see videos about it. Thank you very much. Well, that was a really interesting conversation I just had. I'm really looking forward to where AI is going to be embedded and even more business applications. Yeah, me too. And there is also another field where AI can have a huge impact. OK, that's accessibility. Oh, yeah, of course, yeah. So we're now at the Inclusive Tech lab where we're going to have a chat with Donna Sarkar about this. So let's go inside. So hi, Donna. Thank you so much for joining me today. How are you doing? Awesome. Thank you so much for being here. Yes, really great to be here and have a conversation together with you. So I'm going to ask you a couple of questions. So we start start with the first one. Let's go. Can you tell me who you are and what you do with Microsoft? Absolutely. I'm Donna Sarkar. I lead the accessibility tech program for the company, which means I look after the, let's say, many thousands of products we ship externally, all of our websites and all of our internal tools. So we talked a lot about AI and how it can help people in their daily lives and in their work. Can you explain how AI can also help people with an accessibility needs? Definitely. So I absolutely love both of these topics and the intersection, right, because A is magical and having quite a moment right now. And accessibility, I think, is one of the most fascinating tech areas because you're legitly innovating with the real purpose. You're not making like Uber for fresh fruit, right? It's got like a real reason to exist, all this cool innovation. And when you look at the intersection of the two, you're looking at ways where you're legitly solving the equity divide. And there's three things that. I've seen Microsoft do in the last few years that I think it's really important to call out. The first one that we talk about a lot are captions, right? These are Azure cognitive services, Azure speech services, derived captions and they've been starting to make themselves into make their way into every product. First was of course PowerPoint which if you don't have captions on and PowerPoint by default do it. Second one is teams and the third one and most recent and I think the coolest is Windows 11 because they're available offline. As well, yes. It's really built into the product uses uses the mic, and then yes, yeah, that sounds really great. Yeah, so captions is the first one. The second one is totally nerdy. But I love GitHub copilot. I absolutely love it. I'm a developer, so having this machine generate the first draft of code for me that I can then refine is pretty cool. The part of GitHub copilot that I don't think people know about is GitHub copilot labs. This is the experimental mode of copilot. Where they test all these interesting features and functionality before they go live to everybody. They're part of their nightly insider builds. And there's a brand new one called explain where you could highlight a chunk of code and you'll explain a natural language, what it does. I use it when I'm getting familiar with the new code base or some product that I've never worked with before. The third thing that I've really liked is for neurodivergent folks, right? I'm a neurodivergent person, I have dyslexia, and one of the things I have really appreciated is this thing called teams meeting recap. So say you and I have a teams meeting and we record it. And then I'm thinking. What did I agree to do in the meeting? Right, because you assigned me some homework and I promptly forgot because Neurodivergent urged to forget. But the recap meeting notes actually just call out and say action items assigned to Donna's action items assigned to Hank assigned to everyone. And what a good way to, first of all, and tell people to do work. But also a really, really solid way to make sure that whether you were in the meeting or not in the meeting, you didn't miss anything really obvious. So really sounds amazing. Yeah. So those were the three that I've really loved. Exactly which project really stood out for you? So of course we're looking at recency bias, right? We just had the Bing Edge launch on Tuesday. That was a big deal. That was fun though. My team got to work closely with the product teams to make sure that not only are these new generative AI experiences accessible from a screen reader or, you know, any other disability type point of view, like, yes, I can use them, but they're useful and usable, right? So how can this be really useful? Towards someone who may have say, limited mobility. One of my colleagues, Christina, her arms are paralyzed and she types with her toes. And watching her use this product is really cool because she said Ohh, I now just have to type one sentence. Rather than typing lots of sentences to plan a trip for example, right, we're trying to plan a conference and off site and she's able to do research so quickly now compared to before and the same with me because I will get distracted on anything. So being able to plan just a wheelchair friendly trip to Europe with a whole bunch of takeaways and in line, it's like look up air airfare, look up hotels. It's just a pretty magical experience. So and I think we're only getting started. Like what this thing can do, and that's the big part. The edge part that I found very very fascinating was this feature called summarize where using. I think it's only in the Bing edge or sorry the edge dev build right now, which is you copy in a whole chunk of text and it'll pull out a summary of it. And we just did that with this document that we were supposed to read. It was very long document, it was 12 pages and I thought maybe we can just try the summary feature and. I did the summary feature and I asked my legal friend who's really good at reading documents, is it accurate? And they said actually it's pretty accurate. So you can imagine that's kind of a game changer for people because it gives you this like, easy button shortcut key toward not having to read a large quantity of words. If you are a dyslexic person like me, yeah, it's a major step forward for including everyone here. That's right. And just making life easier for all kinds of people. It's really difficult without including everyone to build these gaps. That's the products. Yeah right. Nearly impossible. Hmm. Ohh, and I'll give you one plug before I leave you. We have our Microsoft ability Summit coming up on March 8th, which is our big Accessibility conference. There will be a lot of surprises, a lot of new things announced, a lot of really cool tech demos, and there are some pretty amazing a list guests. Attending this conference, it's one of my favorite things of the year, so I highly recommend everyone check it out. Just look up ability Summit Microsoft 2023.